---
title: "NLP Basic Learning Notes 01: Introduction and Regular Expressions"
description: "An introductory guide to Natural Language Processing (NLP) covering basic concepts and the application of Regular Expressions (Regex) in Python."
pubDate: "Aug 01 2023"
tags: ["NLP", "Python", "Regex"]
---

# NLP Basic Learning Notes 01: Introduction and Regular Expressions

## 1 Introduction to NLP

NLP (Natural Language Processing) is a critical research area in computer science and artificial intelligence. It focuses on enabling computers to process human language to achieve the goal of "understanding" natural language semantics. Through NLP technologies, humans can communicate more naturally with computers. Additionally, these technologies are widely applied in large-scale data processing fields such as public opinion analysis and knowledge graphs.

This series of learning notes will be based on PyTorch, organizing and summarizing the foundational knowledge of NLP, including Chinese word segmentation (segmentation), part-of-speech tagging (tagging), Named Entity Recognition (NER), keyword extraction, syntax parsing, text vectorization, and sentiment analysis (emotion recognition).

---

## 2 Regular Expressions

Regular expressions, also known as Regex, are a sequence of characters that describe a specific search pattern according to defined syntax. They are used for searching, string matching, and more. Regex is one of the most fundamental tools for processing natural language, helping us extract specific information from text.

### 2.1 Common Regular Expression Syntax

#### 2.1.1 Ordinary Characters

Ordinary characters are typically enclosed in brackets `[]`, indicating a direct match for the content within the brackets.

![pic1](https://inews.gtimg.com/newsapp_ls/0/14413343176/0.png)

#### 2.1.2 Special Characters

Special characters are usually not placed within brackets and represent specific logical meanings.

![pic2](https://inews.gtimg.com/newsapp_ls/0/14413343180/0.png)

The above are just some commonly used Regex syntaxes. For a complete syntax manual, please refer to:

[Regular Expression Manual](https://tool.oschina.net/uploads/apidocs/jquery/regexp.html)

---

## 3 Using Regular Expressions in Python

In Python, regular expressions are implemented via the `re` module. This post primarily introduces the `re.match` and `re.search` functions.

### re.match

The `re.match` function attempts to match a pattern from the beginning of a string. If the match is successful, it returns a match object; otherwise, it returns `None`.

**Function Prototype**

```python
match(pattern, string, flags=0)
```

Where `pattern` is the regular expression template, `string` is the string to be matched, and `flags` are used to control the matching behavior.

**Sample Code**

```python
import re

text_string = 'Web crawlers, also known as web spiders or web robots, are programs or scripts that automatically crawl World Wide Web information according to certain rules. In the FOAF community, they are more often called web chasers. Other less common names include ants, automatic indexers, simulation programs, or worms.'
regex = 'Web'
p_string = text_string.split('.')

for line in p_string:
    if re.match(regex, line.strip()) is not None:
        print(line.strip())
```

**Execution Result**

```
Web crawlers, also known as web spiders or web robots, are programs or scripts that automatically crawl World Wide Web information according to certain rules
```

### re.search

The `re.search` function searches the entire string for a match. If successful, it returns a match object; otherwise, it returns `None`.

**Function Prototype**

```python
search(pattern, string, flags=0)
```

The parameters are basically the same as the `match` function.

**Sample Code**

```python
import re

text_string = 'Web crawlers, also known as web spiders or web robots, are programs or scripts that automatically crawl World Wide Web information according to certain rules. In the FOAF community, they are more often called web chasers. Other less common names include ants, automatic indexers, simulation programs, or worms.'
regex = 'web'
p_string = text_string.split('.')

for line in p_string:
    if re.search(regex, line.strip()) is not None:
        print(line.strip())
```

**Execution Result**

```
Web crawlers, also known as web spiders or web robots, are programs or scripts that automatically crawl World Wide Web information according to certain rules
In the FOAF community, they are more often called web chasers
```

### Using Escape Characters

When we need to match special characters in a string, such as `\`, `[]`, etc., we need to escape them so they lose their special meaning in regular expressions. Consistent with most other languages, regular expressions use the backslash `\` for escaping.